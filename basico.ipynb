{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4158a1be",
   "metadata": {},
   "source": [
    "# Aul√£o LLM's e Agentes - B√°sico de LangChain\n",
    "\n",
    "## Etapa 1 - Pergunta de Engajamento\n",
    "\n",
    "\n",
    "Construir um sistema simples que responde a perguntas sobre um t√≥pico espec√≠fico da escola.\n",
    "\n",
    "Isso √© bem simples, mas √© legal para mostrar como o LangChain organiza, estrutura e facilita o uso de LLMs com prompts reutiliz√°veis.\n",
    "\n",
    "### 1) Sem o Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed393a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui v√£o 3 op√ß√µes de perguntas iniciais, cada uma com foco em uma poss√≠vel principal preocupa√ß√£o do pai:\n",
      "\n",
      "- Op√ß√£o 1 ‚Äî Vestibular/Acad√™mico:\n",
      "‚ÄúQuais s√£o as suas maiores preocupa√ß√µes em rela√ß√£o ao vestibular e ao desempenho acad√™mico do seu filho durante o Ensino M√©dio? Existem √°reas espec√≠ficas em que ele precisa de mais apoio (matem√°tica, l√≠ngua portuguesa, ci√™ncias, reda√ß√£o)?‚Äù\n",
      "\n",
      "- Op√ß√£o 2 ‚Äî Seguran√ßa/Ambiente:\n",
      "‚ÄúQuais s√£o as suas principais preocupa√ß√µes sobre seguran√ßa, bem-estar e o ambiente de aprendizagem no Ensino M√©dio?‚Äù\n",
      "\n",
      "- Op√ß√£o 3 ‚Äî Socializa√ß√£o/Desenvolvimento:\n",
      "‚ÄúQu√£o importante √© para voc√™s o desenvolvimento social do seu filho (amizades, lideran√ßa, atividades extracurriculares) e como a escola pode contribuir para esse aspecto?‚Äù\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI()\n",
    "\n",
    "# Inputs\n",
    "segmento = \"Ensino M√©dio\"\n",
    "\n",
    "# Prompt montado na m√£o - v√™ que aqui eu usei uma f-string \n",
    "prompt = f\"\"\"Voc√™ √© um assistente de admiss√µes de uma escola de excel√™ncia.\n",
    "O pai est√° interessado no {segmento}.\n",
    "Gere 3 op√ß√µes de perguntas iniciais para entender a principal preocupa√ß√£o dele (ex: vestibular, seguran√ßa, socializa√ß√£o).\"\"\"\n",
    "\n",
    "# com o gpt seria assim(apesar de ter v√°rias outras formas):\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    input=prompt\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b70a490",
   "metadata": {},
   "source": [
    "Ou com o Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "832371e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ol√°! √â um prazer receb√™-lo(a) e fico muito feliz com o seu interesse em nossa escola para a jornada do Ensino M√©dio do seu filho(a). Para que eu possa entender melhor suas expectativas e direcionar nossa conversa de forma mais relevante para o senhor(a), gostaria de fazer algumas perguntas iniciais.\n",
      "\n",
      "Aqui est√£o 3 op√ß√µes de perguntas que voc√™ pode usar, cada uma com um foco ligeiramente diferente, mas todas buscando entender a principal preocupa√ß√£o do pai:\n",
      "\n",
      "---\n",
      "\n",
      "**Op√ß√£o 1 (Foco em Futuro/Academia):**\n",
      "\n",
      "\"Para come√ßarmos, ao pensar no Ensino M√©dio e no futuro do seu filho(a), qual √© a principal aspira√ß√£o ou objetivo que o(a) senhor(a) tem em mente para ele(a) ao concluir essa etapa? O que voc√™ espera que ele(a) tenha alcan√ßado ou desenvolvido?\"\n",
      "\n",
      "*   **Por que funciona:** Esta pergunta convida o pai a falar sobre a prepara√ß√£o para o vestibular, universidade, carreira, mas tamb√©m permite que ele aborde habilidades para a vida, independ√™ncia ou outras conquistas acad√™micas e pessoais.\n",
      "\n",
      "---\n",
      "\n",
      "**Op√ß√£o 2 (Foco em Experi√™ncia/Desenvolvimento Integral):**\n",
      "\n",
      "\"Considerando que o Ensino M√©dio √© uma fase de muitas transforma√ß√µes, al√©m do desempenho acad√™mico, como o(a) senhor(a) imagina o ambiente e a experi√™ncia ideal para o desenvolvimento integral do seu filho(a) aqui na escola? H√° alguma √°rea de desenvolvimento pessoal ou social que o(a) senhor(a) considera priorit√°ria nesta fase?\"\n",
      "\n",
      "*   **Por que funciona:** Esta pergunta abre espa√ßo para discuss√µes sobre seguran√ßa, bem-estar emocional, socializa√ß√£o, desenvolvimento de lideran√ßa, intelig√™ncia emocional e constru√ß√£o de car√°ter, sem desconsiderar o acad√™mico.\n",
      "\n",
      "---\n",
      "\n",
      "**Op√ß√£o 3 (Foco em Valores/Parceria Escola-Fam√≠lia):**\n",
      "\n",
      "\"Sabemos que a escolha da escola √© uma decis√£o muito importante. Qual √© o principal valor ou crit√©rio que o(a) senhor(a) busca em uma institui√ß√£o de Ensino M√©dio que ir√° acolher e guiar seu filho(a) neste per√≠odo crucial? Existe algo em particular que o(a) preocupa ou entusiasma mais?\"\n",
      "\n",
      "*   **Por que funciona:** Esta pergunta √© mais abrangente e permite que o pai traga √† tona qualquer preocupa√ß√£o principal que ele tenha, seja ela sobre a metodologia, a cultura da escola, a seguran√ßa, o apoio individualizado, a prepara√ß√£o para o futuro, ou mesmo algo que ele ainda n√£o sabe como verbalizar.\n",
      "\n",
      "---\n",
      "\n",
      "Escolha a que sentir mais natural para iniciar a conversa! Estou √† disposi√ß√£o para ouvir suas impress√µes.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Inputs\n",
    "segmento = \"Ensino M√©dio\"\n",
    "\n",
    "# Prompt montado na m√£o - v√™ que aqui eu usei uma f-string \n",
    "prompt = f\"\"\"Voc√™ √© um assistente de admiss√µes de uma escola de excel√™ncia.\n",
    "O pai est√° interessado no {segmento}.\n",
    "Gere 3 op√ß√µes de perguntas iniciais para entender a principal preocupa√ß√£o dele (ex: vestibular, seguran√ßa, socializa√ß√£o).\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5108ac17",
   "metadata": {},
   "source": [
    "### 2) Com o Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e66177a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claro! Aqui est√£o tr√™s op√ß√µes de perguntas iniciais que podem ajudar a entender as principais preocupa√ß√µes do pai em rela√ß√£o ao Ensino M√©dio:\n",
      "\n",
      "1. **\"Quais s√£o as suas principais expectativas em rela√ß√£o √† prepara√ß√£o do seu filho para o vestibular e o futuro acad√™mico?\"**\n",
      "\n",
      "2. **\"Como voc√™ avalia a import√¢ncia da seguran√ßa e do ambiente escolar na escolha da institui√ß√£o para o Ensino M√©dio?\"**\n",
      "\n",
      "3. **\"De que maneira voc√™ acredita que a socializa√ß√£o e o desenvolvimento de habilidades interpessoais s√£o relevantes para o crescimento do seu filho durante o Ensino M√©dio?\"** \n",
      "\n",
      "Essas perguntas podem ajudar a direcionar a conversa e entender melhor as prioridades do pai.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Inputs\n",
    "segmento = \"Ensino M√©dio\"\n",
    "\n",
    "# usar um template √© mais bizu\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\" Voc√™ √© um assistente de admiss√µes de uma escola de excel√™ncia.\n",
    "    O pai est√° interessado no {segmento}.\n",
    "    Gere 3 op√ß√µes de perguntas iniciais para entender a principal preocupa√ß√£o dele (ex: vestibular, seguran√ßa, socializa√ß√£o).\n",
    "    \"\"\",\n",
    "    input_variables=[\"segmento\"], # colocamos as vari√°veis de input\n",
    ")\n",
    "\n",
    "prompt = template.format(\n",
    "    segmento=segmento,\n",
    ")\n",
    "\n",
    "# gpt\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "# gemini\n",
    "#llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "# esse invoke √© bem √∫til, voc√™ pode usar tanto o \"prompt\" quanto um hist√≥rico de mensagens, etc\n",
    "resposta = llm.invoke(prompt)\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266da6e1",
   "metadata": {},
   "source": [
    "Aqui vemos a 1¬∫ facilidade do langchain, a versatilidade de usar diferentes LLM's;\n",
    "V√™ como √© complicado trocar o modelo de maneira r√°pida e dessa forma a gente s√≥ muda o par√¢metro `llm` e a sa√≠da √© a mesma.\n",
    "\n",
    "Mas temos outra utilidade, e se quisersemos obter uma sa√≠da estruturada, como um JSON?\n",
    "\n",
    "Aqui vamos ver um exemplo b√°sico primeiro, usando a sa√≠da como string mesmo para vermos como funciona o parser e a cadeia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cee35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ol√°! üòä Aqui √© [Seu Nome], assistente de admiss√µes da escola Futuro Brilhante. Fico feliz em saber que voc√™s est√£o considerando nosso Ensino M√©dio! Nossa metodologia √© focada em preparar os alunos para a aprova√ß√£o em universidades federais, com um acompanhamento personalizado e estrat√©gias eficazes. Gostaria de saber quais s√£o as expectativas e objetivos de voc√™s em rela√ß√£o √† educa√ß√£o do seu filho(a)? Estou √† disposi√ß√£o para ajudar!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Atue como um assistente de admiss√µes da escola 'Futuro Brilhante'.\n",
    "    \n",
    "    Sua tarefa √© escrever uma mensagem curta de 'quebra-gelo' para enviar no WhatsApp\n",
    "    para um respons√°vel interessado no segmento: {segmento}.\n",
    "    \n",
    "    Contexto da fam√≠lia:\n",
    "    - O foco principal deles parece ser: {foco_familia}.\n",
    "    - O tom da conversa deve ser: {tom_de_voz}.\n",
    "    \n",
    "    A mensagem deve terminar com uma pergunta aberta para engajar o respons√°vel.\n",
    "    \"\"\",\n",
    "    input_variables=[\"segmento\", \"foco_familia\", \"tom_de_voz\"]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Constru√ß√£o da Cadeia - template + llm + parser de sa√≠da(aqui s√≥ string mesmo)\n",
    "cadeia = template | llm | StrOutputParser()\n",
    "\n",
    "# aqui o invoke a gente pode s√≥ colocar as input variables e usar o template\n",
    "resposta = cadeia.invoke(\n",
    "    {\n",
    "        \"segmento\": \"Ensino M√©dio\",\n",
    "        \"foco_familia\": \"aprova√ß√£o em universidades federais\",\n",
    "        \"tom_de_voz\": \"confiante e profissional\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc6577",
   "metadata": {},
   "source": [
    "## Etapa 2 - Chains com OutputParser\n",
    "üéØ Agora quero tornar o analisador de atendimento da Etapa 1 estruturado e confi√°vel. Queremos que a sa√≠da da LLM n√£o seja apenas um texto solto, mas sim um JSON com os seguintes campos:\n",
    "\n",
    "- `resumo_pedido`: um resumo do que o respons√°vel deseja\n",
    "- `dados_contato`: um dicion√°rio com os dados identificados (Nome, Telefone, Email)\n",
    "- `acao_recomendada`: a pr√≥xima a√ß√£o sugerida para o atendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b610722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acao_recomendada': 'Enviar informa√ß√µes sobre valores e disponibilidade de '\n",
      "                     'vagas.',\n",
      " 'dados_contato': {'Contatos': {'WhatsApp': 'esse mesmo'}, 'Nome': 'Ana'},\n",
      " 'resumo_pedido': 'Ana est√° interessada em saber os valores e a '\n",
      "                  'disponibilidade de vagas para seu filho Pedro, que est√° no '\n",
      "                  '4¬∫ ano, para o per√≠odo da manh√£.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "from typing import Optional\n",
    "\n",
    "# schema da resposta que definimos do Pydantic\n",
    "class AnaliseAtendimento(BaseModel):\n",
    "    resumo_pedido: str = Field(description=\"Resumo da solicita√ß√£o do respons√°vel\")\n",
    "    dados_contato: Optional[dict] = Field(default=None, description=\"Dicion√°rio com chaves Nome, Contatos\") # pode ser nulo\n",
    "    acao_recomendada: str = Field(description=\"A√ß√£o sugerida: Agendar Visita, Enviar PDF ou Ligar\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=AnaliseAtendimento)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"Analise a mensagem de atendimento recebida pelo canal \"{canal}\", referente ao segmento \"{segmento}\".\n",
    "    \n",
    "    Mensagem do Cliente: \"{mensagem}\"\n",
    "    \n",
    "    Extraia as informa√ß√µes e inclua:\n",
    "    - Um resumo do pedido\n",
    "    - Um dicion√°rio com dados de contato\n",
    "    - A a√ß√£o recomendada\n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"canal\", \"segmento\", \"mensagem\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Cadeia: template + llm + parser(aqui o parser √© o JsonOutputParser, que vai gerar o JSON estruturado)\n",
    "cadeia = template | llm | parser\n",
    "\n",
    "resposta = cadeia.invoke({\n",
    "    \"canal\": \"WhatsApp\",\n",
    "    \"segmento\": \"Ensino Fundamental\",\n",
    "    \"mensagem\": \"Oi, sou a Ana. Meu filho Pedro est√° no 4¬∫ ano. Gostaria de saber os valores e se tem vaga de manh√£. Meu zap √© esse mesmo.\"\n",
    "})\n",
    "\n",
    "pprint(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32538f0e",
   "metadata": {},
   "source": [
    "Perceba que definimos os dados de contato como um dicion√°rio de maneira aberta (bem \"ruim\"), mas poderia ser uma classe Pydantic tamb√©m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2433e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acao_recomendada': 'Enviar informa√ß√µes sobre valores e vagas dispon√≠veis '\n",
      "                     'pela manh√£.',\n",
      " 'dados_contato': {'contatos': {'whatsapp': 'o zap √© esse mesmo'},\n",
      "                   'nome': 'Ana'},\n",
      " 'resumo_pedido': 'Cliente Ana solicita informa√ß√µes sobre valores e '\n",
      "                  'disponibilidade de vagas para o filho Pedro no 4¬∫ ano, com '\n",
      "                  'interesse em aulas pela manh√£.'}\n"
     ]
    }
   ],
   "source": [
    "class DadosContato(BaseModel):\n",
    "    nome: Optional[str] = Field(default=None, description=\"Nome do respons√°vel\")\n",
    "    contatos: Optional[dict] = Field(default=None, description=\"Informa√ß√µes de contato (telefone, email, etc.)\")\n",
    "\n",
    "class AnaliseAtendimento(BaseModel):\n",
    "    resumo_pedido: str = Field(description=\"Resumo da solicita√ß√£o do respons√°vel\")\n",
    "    dados_contato: DadosContato = Field(description=\"Dicion√°rio com chaves Nome, Telefone e Email (se encontrados)\")\n",
    "    acao_recomendada: str = Field(description=\"A√ß√£o sugerida: Agendar Visita, Enviar PDF ou Ligar\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=AnaliseAtendimento)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"Analise a mensagem de atendimento recebida pelo canal \"{canal}\", referente ao segmento \"{segmento}\".\n",
    "    \n",
    "    Mensagem do Cliente: \"{mensagem}\"\n",
    "    \n",
    "    Extraia as informa√ß√µes e inclua:\n",
    "    - Um resumo do pedido\n",
    "    - Um dicion√°rio com dados de contato\n",
    "    - A a√ß√£o recomendada\n",
    "\n",
    "    {format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"canal\", \"segmento\", \"mensagem\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "# Cadeia: template + llm + parser(aqui o parser √© o JsonOutputParser, que vai gerar o JSON estruturado)\n",
    "cadeia = template | llm | parser\n",
    "\n",
    "resposta = cadeia.invoke({\n",
    "    \"canal\": \"WhatsApp\",\n",
    "    \"segmento\": \"Ensino Fundamental\",\n",
    "    \"mensagem\": \"Oi, sou a Ana. Meu filho Pedro est√° no 4¬∫ ano. Gostaria de saber os valores e se tem vaga de manh√£. Meu zap √© esse mesmo.\"\n",
    "})\n",
    "\n",
    "pprint(resposta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e51ac5",
   "metadata": {},
   "source": [
    "Com esse exemplo que passamos, voc√™ j√° pode perceber a vantagem disso, bem al√©m de voc√™ enviar isso para um banco de dados, voc√™ pode usar isso para alimentar outras cadeias, agentes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ba688",
   "metadata": {},
   "source": [
    "## Etapa 3 ‚Äî Encadeamento de m√∫ltiplas chains\n",
    "\n",
    "üéØ Vamos criar um sistema de \"Reengajamento Automatizado\" que analisa conversas pausadas, seleciona conte√∫do relevante e gera mensagens de retomada personalizadas.\n",
    "Fluxo:\n",
    "\n",
    "1. Analisa o hist√≥rico e identifica em que fase o lead parou\n",
    "2. Cruza o diagn√≥stico com banco de materiais e escolhe o conte√∫do adequado\n",
    "3. Gera texto de retomada contextualizado de maneira personalizada\n",
    "\n",
    "Para isso, vamos usar o arquivo `marketings.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23b655e",
   "metadata": {},
   "source": [
    "Primeiramente, vamos pensar na classifica√ß√£o do lead, para depois irmos para a sele√ß√£o de conte√∫do e gera√ß√£o da mensagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c3b058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'foco_interesse': 'M√©todos de ensino e materiais utilizados (livros did√°ticos '\n",
      "                   'e projetos maker).',\n",
      " 'hipotese_inatividade': 'O respons√°vel pode estar aguardando a opini√£o da '\n",
      "                         'esposa antes de tomar uma decis√£o.',\n",
      " 'perfil_comunicacao': 'Objetivo',\n",
      " 'resumo_conversa': 'O respons√°vel demonstrou interesse no funcionamento do '\n",
      "                    'ensino fundamental 1, questionou sobre o uso de apostilas '\n",
      "                    'ou livros e mencionou que iria discutir com a esposa.'}\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "TipoPerfil = Literal[\"Objetivo\", \"Detalhista\", \"Afetivo\", \"Desconfiado\", \"Negociador\"]\n",
    "\n",
    "# √† t√≠tulo de exemplo, mostrando como usar um \"dropdown\" de poss√≠veis classifica√ß√µes para perfil_comunicacao - usar o Literal\n",
    "# vai ser mais √∫til nas tags\n",
    "class Diagnostico(BaseModel):\n",
    "    \"\"\"Diagn√≥stico de intera√ß√£o com respons√°vel.\"\"\"\n",
    "    resumo_conversa: str = Field(description=\"Resumo dos principais pontos discutidos na conversa\")\n",
    "    perfil_comunicacao: TipoPerfil = Field(description=\"Estilo de comunica√ß√£o predominante identificado no respons√°vel\")\n",
    "    hipotese_inatividade: str = Field(description=\"Principal motivo prov√°vel para a falta de resposta ou sil√™ncio\")\n",
    "    foco_interesse: str = Field(description=\"Tema ou aspecto que mais despertou interesse\")\n",
    "\n",
    "\n",
    "# Configura√ß√£o do LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "# Parsers\n",
    "parser_diag = JsonOutputParser(pydantic_object=Diagnostico)\n",
    "\n",
    "# Prompt\n",
    "# vamos colocar o hist√≥rico no prompt, mas vamos ver futuramente como melhorar essa abordagem\n",
    "prompt_diag = PromptTemplate(\n",
    "    template=\"\"\"Voc√™ √© um analista de vendas educacionais especializado em diagn√≥stico de leads.\n",
    "Sua tarefa √© analisar o hist√≥rico de conversa abaixo e extrair insights sobre o respons√°vel.\n",
    "Seja preciso, objetivo e baseie-se apenas nas informa√ß√µes fornecidas no hist√≥rico.\n",
    "\n",
    "hist√≥rico:\n",
    "{historico}\n",
    "{format_instructions}\"\"\",\n",
    "    input_variables=[\"historico\"],\n",
    "    partial_variables={\"format_instructions\": parser_diag.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "chain_diag = prompt_diag | llm | parser_diag\n",
    "\n",
    "\n",
    "historico = [\n",
    "    {\"role\": \"assistant\", \"content\": \"Ol√°! Bem-vindo √† Escola Futuro. Como posso ajudar?\"},\n",
    "    {\"role\": \"human\", \"content\": \"Oi, queria saber como funciona o ensino fundamental 1.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Claro! Focamos em autonomia e projetos. Quer agendar uma visita?\"},\n",
    "    {\"role\": \"human\", \"content\": \"Ah, legal. Mas voc√™s usam apostilas ou livros?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Usamos livros did√°ticos e projetos maker.\"},\n",
    "    {\"role\": \"human\", \"content\": \"Entendi. Vou ver com a minha esposa.\"},\n",
    "    {\"role\": \"system\", \"content\": \"Lead inativo h√° 3 dias.\"}\n",
    "]\n",
    "\n",
    "resultado = chain_diag.invoke({\n",
    "    \"historico\": json.dumps(historico, ensure_ascii=False)\n",
    "})\n",
    "\n",
    "pprint(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b8fa4",
   "metadata": {},
   "source": [
    "Ok. Vamos passar para a parte da busca.\n",
    "\n",
    "Aqui vamos passar os conte√∫dos de marketing para o prompt basicamente por did√°tica, obviamente isso n√£o escala, mas voc√™ poderia fazer v√°rias outras abordagens, vou te mostrar 2:\n",
    "\n",
    "1. Na realiza√ß√£o do diagn√≥stico, tente classificar o Lead em tags. Essas tags podem ser usadas para buscar conte√∫dos relacionados que tem as mesmas tags no banco de dados, ent√£o voc√™ faz um ranking e escolhe.\n",
    "\n",
    "2. Vamos futuramente ver RAG (Retrieval-augmented generation), onde voc√™ pode indexar esses conte√∫dos em um vetor e fazer uma busca vetorial para trazer os conte√∫dos mais relevantes. Voc√™ pode fazer uma busca por similaridade com o diagn√≥stico/resumo e trazer os conte√∫dos mais similares. Em palavras simples, voc√™ vai conseguir trazer os conte√∫dos que tem descri√ß√µes mais similares √† descri√ß√£o/resumo do lead. Essa √© a abordagem mais robusta e escal√°vel se voc√™ tem muitos conte√∫dos que s√£o similares entre si(Ex: Pela abordagem 1, tanto faz voc√™ escolher um conte√∫do que tem as tags \"Seguran√ßa\" e \"Infraestrutura\" e outro que tamb√©m tem as mesmas tags).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcbe36d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id_material\": \"MAT_001\",\n",
      "  \"titulo_material\": \"Comparativo: M√©todo Tradicional vs Construtivista\",\n",
      "  \"match_reasoning\": \"Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, proporcionando uma compara√ß√£o clara entre abordagens pedag√≥gicas.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DecisaoConteudo(BaseModel):\n",
    "    id_material: str = Field(description=\"O ID do material escolhido da lista.\")\n",
    "    titulo_material: str = Field(description=\"O t√≠tulo do material escolhido.\")\n",
    "    match_reasoning: str = Field(description=\"Explica√ß√£o breve do motivo deste conte√∫do √© adequado para este perfil de respons√°vel.\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "parser = JsonOutputParser(pydantic_object=DecisaoConteudo)\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Atue como um Especialista de Marketing Escolar.\n",
    "    \n",
    "    Sua miss√£o √© escolher o MELHOR material de apoio para enviar a um lead, baseando-se no perfil dele.\n",
    "    \n",
    "    Perfil do Lead:\n",
    "    - Estilo de Comunica√ß√£o: {perfil_comunicacao}\n",
    "    - Foco de Interesse: {foco_interesse}\n",
    "    - Hipotese para Inatividade: {hipotese_inatividade}\n",
    "\n",
    "    Conte√∫dos dispon√≠veis:\n",
    "    {banco_conteudos}\n",
    "    \n",
    "    Regras:\n",
    "    1. Escolha apenas 1 material que tenha o maior \"Match\" com o interesse do lead.\n",
    "    2. Retorne o ID exato.\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"perfil_comunicacao\", \"foco_interesse\", \"hipotese_inatividade\", \"banco_conteudos\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | llm | parser\n",
    "\n",
    "\n",
    "# Exemplo: Vamos colocar obtidos anteriormente, por exemplo     \n",
    "perfil_comunicacao = \"Objetivo\"\n",
    "foco_interesse = \"M√©todos de ensino e materiais utilizados (livros did√°ticos e projetos maker).\"\n",
    "hipotese_inatividade = \"O respons√°vel pode estar aguardando a opini√£o da esposa antes de tomar uma decis√£o.\"\n",
    "\n",
    "# Carregando o banco de conte√∫dos de marketing\n",
    "banco_conteudos = json.load(open(\"marketings.json\", \"r\", encoding=\"utf-8\"))\n",
    "# passando para string\n",
    "# nesse caso passamos tudo que estava no banco, mas voc√™ poderia passar somente as descri√ß√µes e os IDs\n",
    "banco_conteudos = json.dumps(banco_conteudos, ensure_ascii=False)\n",
    "\n",
    "resultado = chain.invoke({\n",
    "    \"perfil_comunicacao\": perfil_comunicacao,\n",
    "    \"foco_interesse\": foco_interesse,\n",
    "    \"hipotese_inatividade\": hipotese_inatividade,\n",
    "    \"banco_conteudos\": banco_conteudos\n",
    "})\n",
    "\n",
    "print(json.dumps(resultado, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164b27e",
   "metadata": {},
   "source": [
    "Massa! Vamos ver agora a parte da mensagem final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "013fd600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'texto': 'Ol√°! Espero que voc√™ esteja bem. Queria retomar nosso contato e compartilhar um material que acredito que ser√° muito √∫til para voc√™. Ele aborda um comparativo entre o M√©todo Tradicional e o Construtivista, focando nas abordagens pedag√≥gicas que voc√™ demonstrou interesse. Estou √† disposi√ß√£o para conversar mais sobre isso!'}\n"
     ]
    }
   ],
   "source": [
    "class MensagemResgate(BaseModel):\n",
    "    texto: str = Field(description=\"Texto da mensagem de resgate para o WhatsApp\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7) # vamos colocar uma temperatura maior para ser mais criativo e natural\n",
    "parser = JsonOutputParser(pydantic_object=MensagemResgate)\n",
    "\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Atue como um Resgatador de Lead por meio de uma mensagem de WhatsApp.\n",
    "    Escreva uma mensagem de retomada de contato juntamente com o conte√∫do de marketing disponibilizado.\n",
    "    O conte√∫do vai ser enviado junto com a mensagem, ent√£o n√£o repita informa√ß√µes do material.\n",
    "\n",
    "    Conte√∫do:\n",
    "    - T√≠tulo: {titulo_material}\n",
    "    - Motivo para a escolha do conte√∫do: {match_reasoning}\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"perfil\", \"interesse\", \"motivo_pausa\", \"titulo_material\", \"match_reasoning\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | llm | parser\n",
    "\n",
    "# vamos supor que os resultados da chain anterior foram:\n",
    "titulo_material = \"Comparativo: M√©todo Tradicional vs Construtivista\"\n",
    "match_reasoning = \"Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, proporcionando uma compara√ß√£o clara entre abordagens pedag√≥gicas.\"\n",
    "\n",
    "mensagem = chain.invoke({\n",
    "    \"titulo_material\": titulo_material,\n",
    "    \"match_reasoning\": match_reasoning\n",
    "})\n",
    "\n",
    "print(mensagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc53e64",
   "metadata": {},
   "source": [
    "Beleza, mas como eu fa√ßo esse processo todo de maneira encadeada? Ou seja, quero que a sa√≠da de uma etapa seja a entrada da pr√≥xima. Vou reescrever o c√≥digo todo aqui para ficar mais claro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834528a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"historico\": [\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Ol√°! Bem-vindo √† Escola Futuro. Como posso ajudar?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"human\",\n",
      "      \"content\": \"Oi, queria saber como funciona o ensino fundamental 1.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Claro! Focamos em autonomia e projetos. Quer agendar uma visita?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"human\",\n",
      "      \"content\": \"Ah, legal. Mas voc√™s usam apostilas ou livros?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Usamos livros did√°ticos e projetos maker.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"human\",\n",
      "      \"content\": \"Entendi. Vou ver com a minha esposa.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"Lead inativo h√° 3 dias.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"historico\": [\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Ol√°! Bem-vindo √† Escola Futuro. Como posso ajudar?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"human\",\n",
      "      \"content\": \"Oi, queria saber como funciona o ensino fundamental 1.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Claro! Focamos em autonomia e projetos. Quer agendar uma visita?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"human\",\n",
      "      \"content\": \"Ah, legal. Mas voc√™s usam apostilas ou livros?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Usamos livros did√°ticos e projetos maker.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"human\",\n",
      "      \"content\": \"Entendi. Vou ver com a minha esposa.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"Lead inativo h√° 3 dias.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Voc√™ √© um analista de vendas educacionais especializado em diagn√≥stico de leads.\\nSua tarefa √© analisar o hist√≥rico de conversa abaixo e extrair insights sobre o respons√°vel.\\nSeja preciso, objetivo e baseie-se apenas nas informa√ß√µes fornecidas no hist√≥rico.\\n\\nhist√≥rico:\\n[{'role': 'assistant', 'content': 'Ol√°! Bem-vindo √† Escola Futuro. Como posso ajudar?'}, {'role': 'human', 'content': 'Oi, queria saber como funciona o ensino fundamental 1.'}, {'role': 'assistant', 'content': 'Claro! Focamos em autonomia e projetos. Quer agendar uma visita?'}, {'role': 'human', 'content': 'Ah, legal. Mas voc√™s usam apostilas ou livros?'}, {'role': 'assistant', 'content': 'Usamos livros did√°ticos e projetos maker.'}, {'role': 'human', 'content': 'Entendi. Vou ver com a minha esposa.'}, {'role': 'system', 'content': 'Lead inativo h√° 3 dias.'}]\\nSTRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \\\"Here is the JSON:\\\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]} the object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only ‚Äî do not include any backticks or Markdown in your output):\\n```\\n{\\\"description\\\": \\\"Diagn√≥stico de intera√ß√£o com respons√°vel.\\\", \\\"properties\\\": {\\\"resumo_conversa\\\": {\\\"description\\\": \\\"Resumo dos principais pontos discutidos na conversa\\\", \\\"title\\\": \\\"Resumo Conversa\\\", \\\"type\\\": \\\"string\\\"}, \\\"perfil_comunicacao\\\": {\\\"description\\\": \\\"Estilo de comunica√ß√£o predominante identificado no respons√°vel\\\", \\\"enum\\\": [\\\"Objetivo\\\", \\\"Detalhista\\\", \\\"Afetivo\\\", \\\"Desconfiado\\\", \\\"Negociador\\\"], \\\"title\\\": \\\"Perfil Comunicacao\\\", \\\"type\\\": \\\"string\\\"}, \\\"hipotese_inatividade\\\": {\\\"description\\\": \\\"Principal motivo prov√°vel para a falta de resposta ou sil√™ncio\\\", \\\"title\\\": \\\"Hipotese Inatividade\\\", \\\"type\\\": \\\"string\\\"}, \\\"foco_interesse\\\": {\\\"description\\\": \\\"Tema ou aspecto que mais despertou interesse\\\", \\\"title\\\": \\\"Foco Interesse\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"resumo_conversa\\\", \\\"perfil_comunicacao\\\", \\\"hipotese_inatividade\\\", \\\"foco_interesse\\\"]}\\n```\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.47s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"resumo_conversa\\\":\\\"O respons√°vel demonstrou interesse em saber como funciona o ensino fundamental 1, questionou sobre o uso de apostilas ou livros e mencionou que iria discutir com a esposa antes de tomar uma decis√£o.\\\",\\\"perfil_comunicacao\\\":\\\"Objetivo\\\",\\\"hipotese_inatividade\\\":\\\"O respons√°vel pode estar aguardando uma decis√£o conjunta com a esposa antes de prosseguir.\\\",\\\"foco_interesse\\\":\\\"M√©todos de ensino e materiais utilizados na escola.\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"resumo_conversa\\\":\\\"O respons√°vel demonstrou interesse em saber como funciona o ensino fundamental 1, questionou sobre o uso de apostilas ou livros e mencionou que iria discutir com a esposa antes de tomar uma decis√£o.\\\",\\\"perfil_comunicacao\\\":\\\"Objetivo\\\",\\\"hipotese_inatividade\\\":\\\"O respons√°vel pode estar aguardando uma decis√£o conjunta com a esposa antes de prosseguir.\\\",\\\"foco_interesse\\\":\\\"M√©todos de ensino e materiais utilizados na escola.\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 93,\n",
      "                \"prompt_tokens\": 668,\n",
      "                \"total_tokens\": 761,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_provider\": \"openai\",\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_a460d7e2b7\",\n",
      "              \"id\": \"chatcmpl-CmnPO2fwOZY7gHi5iKR2vix3HlNa0\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"lc_run--019b1ea5-434a-77f0-a50f-3745ca65e435-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 668,\n",
      "              \"output_tokens\": 93,\n",
      "              \"total_tokens\": 761,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 93,\n",
      "      \"prompt_tokens\": 668,\n",
      "      \"total_tokens\": 761,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_a460d7e2b7\",\n",
      "    \"id\": \"chatcmpl-CmnPO2fwOZY7gHi5iKR2vix3HlNa0\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"resumo_conversa\": \"O respons√°vel demonstrou interesse em saber como funciona o ensino fundamental 1, questionou sobre o uso de apostilas ou livros e mencionou que iria discutir com a esposa antes de tomar uma decis√£o.\",\n",
      "  \"perfil_comunicacao\": \"Objetivo\",\n",
      "  \"hipotese_inatividade\": \"O respons√°vel pode estar aguardando uma decis√£o conjunta com a esposa antes de prosseguir.\",\n",
      "  \"foco_interesse\": \"M√©todos de ensino e materiais utilizados na escola.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"resumo_conversa\": \"O respons√°vel demonstrou interesse em saber como funciona o ensino fundamental 1, questionou sobre o uso de apostilas ou livros e mencionou que iria discutir com a esposa antes de tomar uma decis√£o.\",\n",
      "  \"perfil_comunicacao\": \"Objetivo\",\n",
      "  \"hipotese_inatividade\": \"O respons√°vel pode estar aguardando uma decis√£o conjunta com a esposa antes de prosseguir.\",\n",
      "  \"foco_interesse\": \"M√©todos de ensino e materiais utilizados na escola.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n    Atue como um Especialista de Marketing Escolar.\\n\\n    Sua miss√£o √© escolher o MELHOR material de apoio para enviar a um lead, baseando-se no perfil dele.\\n\\n    Perfil do Lead:\\n    - Estilo de Comunica√ß√£o: Objetivo\\n    - Foco de Interesse: M√©todos de ensino e materiais utilizados na escola.\\n    - Hipotese para Inatividade: O respons√°vel pode estar aguardando uma decis√£o conjunta com a esposa antes de prosseguir.\\n\\n    Conte√∫dos dispon√≠veis:\\n    [{\\\"id\\\": \\\"MAT_001\\\", \\\"titulo\\\": \\\"Comparativo: M√©todo Tradicional vs Construtivista\\\", \\\"tags\\\": [\\\"pedag√≥gico\\\", \\\"metodologia\\\"], \\\"formato\\\": \\\"Infogr√°fico PDF\\\"}, {\\\"id\\\": \\\"MAT_002\\\", \\\"titulo\\\": \\\"Calculadora de Investimento e Descontos\\\", \\\"tags\\\": [\\\"financeiro\\\", \\\"pre√ßo\\\", \\\"bolsa\\\"], \\\"formato\\\": \\\"Link Interativo\\\"}, {\\\"id\\\": \\\"MAT_003\\\", \\\"titulo\\\": \\\"V√≠deo: Um dia na vida dos alunos\\\", \\\"tags\\\": [\\\"rotina\\\", \\\"ambiente\\\", \\\"seguran√ßa\\\"], \\\"formato\\\": \\\"V√≠deo Youtube\\\"}, {\\\"id\\\": \\\"MAT_004\\\", \\\"titulo\\\": \\\"Resultados no Vestibular 2024\\\", \\\"tags\\\": [\\\"performance\\\", \\\"resultado\\\"], \\\"formato\\\": \\\"PDF\\\"}]\\n\\n    Regras:\\n    1. Escolha apenas 1 material que tenha o maior \\\"Match\\\" com o interesse do lead.\\n    2. Retorne o ID exato.\\n\\n    STRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \\\"Here is the JSON:\\\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]} the object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only ‚Äî do not include any backticks or Markdown in your output):\\n```\\n{\\\"properties\\\": {\\\"id_material\\\": {\\\"description\\\": \\\"O ID do material escolhido da lista.\\\", \\\"title\\\": \\\"Id Material\\\", \\\"type\\\": \\\"string\\\"}, \\\"titulo_material\\\": {\\\"description\\\": \\\"O t√≠tulo do material escolhido.\\\", \\\"title\\\": \\\"Titulo Material\\\", \\\"type\\\": \\\"string\\\"}, \\\"match_reasoning\\\": {\\\"description\\\": \\\"Explica√ß√£o breve do motivo deste conte√∫do √© adequado para este perfil de respons√°vel.\\\", \\\"title\\\": \\\"Match Reasoning\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"id_material\\\", \\\"titulo_material\\\", \\\"match_reasoning\\\"]}\\n```\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [1.63s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"id_material\\\":\\\"MAT_001\\\",\\\"titulo_material\\\":\\\"Comparativo: M√©todo Tradicional vs Construtivista\\\",\\\"match_reasoning\\\":\\\"Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, permitindo uma an√°lise objetiva das abordagens pedag√≥gicas da escola.\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"id_material\\\":\\\"MAT_001\\\",\\\"titulo_material\\\":\\\"Comparativo: M√©todo Tradicional vs Construtivista\\\",\\\"match_reasoning\\\":\\\"Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, permitindo uma an√°lise objetiva das abordagens pedag√≥gicas da escola.\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 59,\n",
      "                \"prompt_tokens\": 681,\n",
      "                \"total_tokens\": 740,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_provider\": \"openai\",\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_aa07c96156\",\n",
      "              \"id\": \"chatcmpl-CmnPQ3vL81R9VPqNyT2tCJixc3DWN\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"lc_run--019b1ea5-4cf5-7c72-a66a-9676c63095dc-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 681,\n",
      "              \"output_tokens\": 59,\n",
      "              \"total_tokens\": 740,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 59,\n",
      "      \"prompt_tokens\": 681,\n",
      "      \"total_tokens\": 740,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_aa07c96156\",\n",
      "    \"id\": \"chatcmpl-CmnPQ3vL81R9VPqNyT2tCJixc3DWN\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"id_material\": \"MAT_001\",\n",
      "  \"titulo_material\": \"Comparativo: M√©todo Tradicional vs Construtivista\",\n",
      "  \"match_reasoning\": \"Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, permitindo uma an√°lise objetiva das abordagens pedag√≥gicas da escola.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"id_material\": \"MAT_001\",\n",
      "  \"titulo_material\": \"Comparativo: M√©todo Tradicional vs Construtivista\",\n",
      "  \"match_reasoning\": \"Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, permitindo uma an√°lise objetiva das abordagens pedag√≥gicas da escola.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n    Atue como um Resgatador de Lead por meio de uma mensagem de WhatsApp.\\n    Escreva uma mensagem de retomada de contato juntamente com o conte√∫do de marketing disponibilizado.\\n    O conte√∫do vai ser enviado junto com a mensagem, ent√£o n√£o repita informa√ß√µes do material.\\n\\n    Conte√∫do:\\n    - T√≠tulo: Comparativo: M√©todo Tradicional vs Construtivista\\n    - Motivo para a escolha do conte√∫do: Este material aborda diretamente os m√©todos de ensino, que √© o foco de interesse do lead, permitindo uma an√°lise objetiva das abordagens pedag√≥gicas da escola.\\n\\n    STRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \\\"Here is the JSON:\\\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]} the object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only ‚Äî do not include any backticks or Markdown in your output):\\n```\\n{\\\"properties\\\": {\\\"texto\\\": {\\\"description\\\": \\\"Texto da mensagem de resgate para o WhatsApp\\\", \\\"title\\\": \\\"Texto\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"texto\\\"]}\\n```\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:ChatOpenAI] [2.35s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\\"texto\\\":\\\"Ol√°! Tudo bem? Espero que voc√™ esteja tendo um √≥timo dia! Eu gostaria de retomar nosso contato e compartilhar um material interessante que aborda o comparativo entre o M√©todo Tradicional e o Construtivista. Acredito que voc√™ achar√° √∫til para entender melhor as abordagens pedag√≥gicas que estamos discutindo. Estou √† disposi√ß√£o para conversar mais sobre o assunto!\\\"}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\\"texto\\\":\\\"Ol√°! Tudo bem? Espero que voc√™ esteja tendo um √≥timo dia! Eu gostaria de retomar nosso contato e compartilhar um material interessante que aborda o comparativo entre o M√©todo Tradicional e o Construtivista. Acredito que voc√™ achar√° √∫til para entender melhor as abordagens pedag√≥gicas que estamos discutindo. Estou √† disposi√ß√£o para conversar mais sobre o assunto!\\\"}\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 78,\n",
      "                \"prompt_tokens\": 412,\n",
      "                \"total_tokens\": 490,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_provider\": \"openai\",\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_db64b059be\",\n",
      "              \"id\": \"chatcmpl-CmnPShf64ato2ZfA2zrKVyqrUDlzG\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"lc_run--019b1ea5-5358-7662-bcea-3b8b2a6f5f3b-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 412,\n",
      "              \"output_tokens\": 78,\n",
      "              \"total_tokens\": 490,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 78,\n",
      "      \"prompt_tokens\": 412,\n",
      "      \"total_tokens\": 490,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_provider\": \"openai\",\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_db64b059be\",\n",
      "    \"id\": \"chatcmpl-CmnPShf64ato2ZfA2zrKVyqrUDlzG\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:JsonOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"texto\": \"Ol√°! Tudo bem? Espero que voc√™ esteja tendo um √≥timo dia! Eu gostaria de retomar nosso contato e compartilhar um material interessante que aborda o comparativo entre o M√©todo Tradicional e o Construtivista. Acredito que voc√™ achar√° √∫til para entender melhor as abordagens pedag√≥gicas que estamos discutindo. Estou √† disposi√ß√£o para conversar mais sobre o assunto!\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.45s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"texto\": \"Ol√°! Tudo bem? Espero que voc√™ esteja tendo um √≥timo dia! Eu gostaria de retomar nosso contato e compartilhar um material interessante que aborda o comparativo entre o M√©todo Tradicional e o Construtivista. Acredito que voc√™ achar√° √∫til para entender melhor as abordagens pedag√≥gicas que estamos discutindo. Estou √† disposi√ß√£o para conversar mais sobre o assunto!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# para ver o processo ocorrendo por baixo dos panos, vamos colocar o set_debug\n",
    "\n",
    "from langchain_core.globals import set_debug\n",
    "set_debug(True)\n",
    "\n",
    "# Carregando o banco de conte√∫dos de marketing\n",
    "banco_conteudos = json.load(open(\"marketings.json\", \"r\", encoding=\"utf-8\"))\n",
    "# passando para string\n",
    "# nesse caso passamos tudo que estava no banco, mas voc√™ poderia passar somente as descri√ß√µes e os IDs\n",
    "banco_conteudos = json.dumps(banco_conteudos, ensure_ascii=False)\n",
    "\n",
    "TipoPerfil = Literal[\"Objetivo\", \"Detalhista\", \"Afetivo\", \"Desconfiado\", \"Negociador\"]\n",
    "\n",
    "class Diagnostico(BaseModel):\n",
    "    \"\"\"Diagn√≥stico de intera√ß√£o com respons√°vel.\"\"\"\n",
    "    resumo_conversa: str = Field(description=\"Resumo dos principais pontos discutidos na conversa\")\n",
    "    perfil_comunicacao: TipoPerfil = Field(description=\"Estilo de comunica√ß√£o predominante identificado no respons√°vel\")\n",
    "    hipotese_inatividade: str = Field(description=\"Principal motivo prov√°vel para a falta de resposta ou sil√™ncio\")\n",
    "    foco_interesse: str = Field(description=\"Tema ou aspecto que mais despertou interesse\")\n",
    "\n",
    "class DecisaoConteudo(BaseModel):\n",
    "    id_material: str = Field(description=\"O ID do material escolhido da lista.\")\n",
    "    titulo_material: str = Field(description=\"O t√≠tulo do material escolhido.\")\n",
    "    match_reasoning: str = Field(description=\"Explica√ß√£o breve do motivo deste conte√∫do √© adequado para este perfil de respons√°vel.\")\n",
    "\n",
    "class MensagemResgate(BaseModel):\n",
    "    texto: str = Field(description=\"Texto da mensagem de resgate para o WhatsApp\")\n",
    "\n",
    "# llm's\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "llm_resgate = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7) # mais criativo para resgate\n",
    "\n",
    "# parsers\n",
    "parser_diag = JsonOutputParser(pydantic_object=Diagnostico)\n",
    "parser_conteudo = JsonOutputParser(pydantic_object=DecisaoConteudo)\n",
    "parser_resgate = JsonOutputParser(pydantic_object=MensagemResgate)\n",
    "\n",
    "# templates\n",
    "template_diag = PromptTemplate(\n",
    "    template=\"\"\"Voc√™ √© um analista de vendas educacionais especializado em diagn√≥stico de leads.\n",
    "Sua tarefa √© analisar o hist√≥rico de conversa abaixo e extrair insights sobre o respons√°vel.\n",
    "Seja preciso, objetivo e baseie-se apenas nas informa√ß√µes fornecidas no hist√≥rico.\n",
    "\n",
    "hist√≥rico:\n",
    "{historico}\n",
    "{format_instructions}\"\"\",\n",
    "    input_variables=[\"historico\"],\n",
    "    partial_variables={\"format_instructions\": parser_diag.get_format_instructions()}\n",
    ")\n",
    "\n",
    "template_conteudo = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Atue como um Especialista de Marketing Escolar.\n",
    "    \n",
    "    Sua miss√£o √© escolher o MELHOR material de apoio para enviar a um lead, baseando-se no perfil dele.\n",
    "    \n",
    "    Perfil do Lead:\n",
    "    - Estilo de Comunica√ß√£o: {perfil_comunicacao}\n",
    "    - Foco de Interesse: {foco_interesse}\n",
    "    - Hipotese para Inatividade: {hipotese_inatividade}\n",
    "\n",
    "    Conte√∫dos dispon√≠veis:\n",
    "    {banco_conteudos}\n",
    "    \n",
    "    Regras:\n",
    "    1. Escolha apenas 1 material que tenha o maior \\\"Match\\\" com o interesse do lead.\n",
    "    2. Retorne o ID exato.\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"perfil_comunicacao\", \"foco_interesse\", \"hipotese_inatividade\", \"banco_conteudos\"],\n",
    "    partial_variables={\n",
    "        \"banco_conteudos\": banco_conteudos,\n",
    "        \"format_instructions\": parser_conteudo.get_format_instructions()\n",
    "    }\n",
    ")\n",
    "template_resgate = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Atue como um Resgatador de Lead por meio de uma mensagem de WhatsApp.\n",
    "    Escreva uma mensagem de retomada de contato juntamente com o conte√∫do de marketing disponibilizado.\n",
    "    O conte√∫do vai ser enviado junto com a mensagem, ent√£o n√£o repita informa√ß√µes do material.\n",
    "\n",
    "    Conte√∫do:\n",
    "    - T√≠tulo: {titulo_material}\n",
    "    - Motivo para a escolha do conte√∫do: {match_reasoning}\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"perfil_comunicacao\", \"foco_interesse\", \"hipotese_inatividade\", \"titulo_material\", \"match_reasoning\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# chains\n",
    "chain_diag = template_diag | llm | parser_diag\n",
    "chain_conteudo = template_conteudo | llm | parser_conteudo\n",
    "chain_resgate = template_resgate | llm_resgate | parser_resgate\n",
    "# principal agora;\n",
    "chain_principal = chain_diag | chain_conteudo | chain_resgate\n",
    "\n",
    "historico = [\n",
    "    {\"role\": \"assistant\", \"content\": \"Ol√°! Bem-vindo √† Escola Futuro. Como posso ajudar?\"},\n",
    "    {\"role\": \"human\", \"content\": \"Oi, queria saber como funciona o ensino fundamental 1.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Claro! Focamos em autonomia e projetos. Quer agendar uma visita?\"},\n",
    "    {\"role\": \"human\", \"content\": \"Ah, legal. Mas voc√™s usam apostilas ou livros?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Usamos livros did√°ticos e projetos maker.\"},\n",
    "    {\"role\": \"human\", \"content\": \"Entendi. Vou ver com a minha esposa.\"},\n",
    "    {\"role\": \"system\", \"content\": \"Lead inativo h√° 3 dias.\"}\n",
    "]\n",
    "\n",
    "mensagem = chain_principal.invoke({\n",
    "    \"historico\": historico,\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170f7d8",
   "metadata": {},
   "source": [
    "`Output Final`:\n",
    "\n",
    "_Ol√°! Tudo bem? Espero que voc√™ esteja tendo um √≥timo dia! Eu gostaria de retomar nosso contato e compartilhar um material interessante que aborda o comparativo entre o M√©todo Tradicional e o Construtivista. Acredito que voc√™ achar√° √∫til para entender melhor as abordagens pedag√≥gicas que estamos discutindo. Estou √† disposi√ß√£o para conversar mais sobre o assunto!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c309a9",
   "metadata": {},
   "source": [
    "_Por que n√£o fazer de maneira unificada? Sla, um √∫nico prompt que fa√ßa tudo?_ \n",
    "\n",
    "Desse jeito voc√™ consegue trabalhar de maneira mais individual em cada etapa, testar, validar, ajustar, etc. O que √© mais valioso √© que voc√™ consegue separar as etapas de pensamento da IA e n√£o fazer com que ela pense do jeito dela. Voc√™ tem bem mais controle de tudo que t√° acontecendo. Al√©m disso, voc√™ pode reutilizar essas cadeias em outros fluxos tamb√©m. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
